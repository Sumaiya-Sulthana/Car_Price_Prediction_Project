{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Price Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Understanding and Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# reading the dataset\n",
    "cars = pd.read_csv(\"CarPrice_Assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the dataset: 205 rows, 26 columns, no null values\n",
    "print(cars.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symboling: -2 (least risky) to +3 most risky\n",
    "# Most cars are 0,1,2\n",
    "cars['symboling'].astype('category').value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspiration: An (internal combustion) engine property showing \n",
    "# whether the oxygen intake is through standard (atmospheric pressure)\n",
    "# or through turbocharging (pressurised oxygen intake)\n",
    "\n",
    "cars['aspiration'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drivewheel: frontwheel, rarewheel or four-wheel drive \n",
    "cars['drivewheel'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wheelbase: distance between centre of front and rearwheels\n",
    "sns.distplot(cars['wheelbase'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curbweight: weight of car without occupants or baggage\n",
    "sns.distplot(cars['curbweight'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stroke: volume of the engine (the distance traveled by the \n",
    "# piston in each cycle)\n",
    "sns.distplot(cars['stroke'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression ration: ration of volume of compression chamber \n",
    "# at largest capacity to least capacity\n",
    "sns.distplot(cars['compressionratio'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable: price of car\n",
    "sns.distplot(cars['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration\n",
    "\n",
    "To perform linear regression, the (numeric) target variable should be linearly related to *at least one another numeric variable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all numeric (float and int) variables in the dataset\n",
    "cars_numeric = cars.select_dtypes(include=['float64', 'int'])\n",
    "cars_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping symboling and car_ID \n",
    "cars_numeric = cars_numeric.drop(['symboling', 'car_ID'], axis=1)\n",
    "cars_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paiwise scatter plot\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.pairplot(cars_numeric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "cor = cars_numeric.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlations on a heatmap\n",
    "\n",
    "# figure size\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# heatmap\n",
    "sns.heatmap(cor, cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable formats\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting symboling to categorical\n",
    "cars['symboling'] = cars['symboling'].astype('object')\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CarName: first few entries\n",
    "cars['CarName'][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting carname\n",
    "\n",
    "# Method 1: str.split() by space\n",
    "carnames = cars['CarName'].apply(lambda x: x.split(\" \")[0])\n",
    "carnames[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Use regular expressions\n",
    "import re\n",
    "\n",
    "# regex: any alphanumeric sequence before a space, may contain a hyphen\n",
    "p = re.compile(r'\\w+-?\\w+')\n",
    "carnames = cars['CarName'].apply(lambda x: re.findall(p, x)[0])\n",
    "print(carnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column car_company\n",
    "cars['car_company'] = cars['CarName'].apply(lambda x: re.findall(p, x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all values \n",
    "cars['car_company'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing misspelled car_company names\n",
    "\n",
    "# volkswagen\n",
    "cars.loc[(cars['car_company'] == \"vw\") | \n",
    "         (cars['car_company'] == \"vokswagen\")\n",
    "         , 'car_company'] = 'volkswagen'\n",
    "\n",
    "# porsche\n",
    "cars.loc[cars['car_company'] == \"porcshce\", 'car_company'] = 'porsche'\n",
    "\n",
    "# toyota\n",
    "cars.loc[cars['car_company'] == \"toyouta\", 'car_company'] = 'toyota'\n",
    "\n",
    "# nissan\n",
    "cars.loc[cars['car_company'] == \"Nissan\", 'car_company'] = 'nissan'\n",
    "\n",
    "# mazda\n",
    "cars.loc[cars['car_company'] == \"maxda\", 'car_company'] = 'mazda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['car_company'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop carname variable\n",
    "cars = cars.drop('CarName', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation \n",
    "\n",
    "\n",
    "#### Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X = cars.loc[:, ['symboling', 'fueltype', 'aspiration', 'doornumber',\n",
    "       'carbody', 'drivewheel', 'enginelocation', 'wheelbase', 'carlength',\n",
    "       'carwidth', 'carheight', 'curbweight', 'enginetype', 'cylindernumber',\n",
    "       'enginesize', 'fuelsystem', 'boreratio', 'stroke', 'compressionratio',\n",
    "       'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
    "       'car_company']]\n",
    "\n",
    "y = cars['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy variables for categorical variables\n",
    "\n",
    "# subset all categorical variables\n",
    "cars_categorical = X.select_dtypes(include=['object'])\n",
    "cars_categorical.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into dummies\n",
    "cars_dummies = pd.get_dummies(cars_categorical, drop_first=True)\n",
    "cars_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical variables \n",
    "X = X.drop(list(cars_categorical.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dummy variables with X\n",
    "X = pd.concat([X, cars_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# storing column names in cols, since column names are (annoyingly) lost after \n",
    "# scaling (the df is converted to a numpy array)\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(scale(X))\n",
    "X.columns = cols\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the first model with all the features\n",
    "\n",
    "# instantiate\n",
    "lm = LinearRegression()\n",
    "\n",
    "# fit\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients and intercept\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(r2_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building Using RFE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with 15 features\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# RFE with 15 features\n",
    "lm = LinearRegression()\n",
    "rfe_15 = RFE(lm, 15)\n",
    "\n",
    "# fit with 15 features\n",
    "rfe_15.fit(X_train, y_train)\n",
    "\n",
    "# Printing the boolean results\n",
    "print(rfe_15.support_)           \n",
    "print(rfe_15.ranking_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making predictions using rfe model\n",
    "y_pred = rfe_15.predict(X_test)\n",
    "\n",
    "# r-squared\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with 6 features\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# RFE with 6 features\n",
    "lm = LinearRegression()\n",
    "rfe_6 = RFE(lm, 6)\n",
    "\n",
    "# fit with 6 features\n",
    "rfe_6.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rfe_6.predict(X_test)\n",
    "\n",
    "# r-squared\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "# subset the features selected by rfe_15\n",
    "col_15 = X_train.columns[rfe_15.support_]\n",
    "\n",
    "# subsetting training data for 15 selected columns\n",
    "X_train_rfe_15 = X_train[col_15]\n",
    "\n",
    "# add a constant to the model\n",
    "X_train_rfe_15 = sm.add_constant(X_train_rfe_15)\n",
    "X_train_rfe_15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model with 15 variables\n",
    "lm_15 = sm.OLS(y_train, X_train_rfe_15).fit()   \n",
    "print(lm_15.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions using rfe_15 sm model\n",
    "X_test_rfe_15 = X_test[col_15]\n",
    "\n",
    "\n",
    "# # Adding a constant variable \n",
    "X_test_rfe_15 = sm.add_constant(X_test_rfe_15, has_constant='add')\n",
    "X_test_rfe_15.info()\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "y_pred = lm_15.predict(X_test_rfe_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r-squared\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the features selected by rfe_6\n",
    "col_6 = X_train.columns[rfe_6.support_]\n",
    "\n",
    "# subsetting training data for 6 selected columns\n",
    "X_train_rfe_6 = X_train[col_6]\n",
    "\n",
    "# add a constant to the model\n",
    "X_train_rfe_6 = sm.add_constant(X_train_rfe_6)\n",
    "\n",
    "\n",
    "# fitting the model with 6 variables\n",
    "lm_6 = sm.OLS(y_train, X_train_rfe_6).fit()   \n",
    "print(lm_6.summary())\n",
    "\n",
    "\n",
    "# making predictions using rfe_6 sm model\n",
    "X_test_rfe_6 = X_test[col_6]\n",
    "\n",
    "\n",
    "# Adding a constant  \n",
    "X_test_rfe_6 = sm.add_constant(X_test_rfe_6, has_constant='add')\n",
    "X_test_rfe_6.info()\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "y_pred = lm_6.predict(X_test_rfe_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score for 6 variables\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the optimal number of features\n",
    "\n",
    "Now, we have seen that the adjusted r-squared varies from about 93.3 to 88 as we go from 15 to 6 features, one way to choose the optimal number of features is to make a plot between n_features and adjusted r-squared, and then choose the value of n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_list = list(range(4, 20))\n",
    "adjusted_r2 = []\n",
    "r2 = []\n",
    "test_r2 = []\n",
    "\n",
    "for n_features in range(4, 20):\n",
    "\n",
    "    # RFE with n features\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # specify number of features\n",
    "    rfe_n = RFE(lm, n_features)\n",
    "\n",
    "    # fit with n features\n",
    "    rfe_n.fit(X_train, y_train)\n",
    "\n",
    "    # subset the features selected by rfe_6\n",
    "    col_n = X_train.columns[rfe_n.support_]\n",
    "\n",
    "    # subsetting training data for 6 selected columns\n",
    "    X_train_rfe_n = X_train[col_n]\n",
    "\n",
    "    # add a constant to the model\n",
    "    X_train_rfe_n = sm.add_constant(X_train_rfe_n)\n",
    "\n",
    "\n",
    "    # fitting the model with 6 variables\n",
    "    lm_n = sm.OLS(y_train, X_train_rfe_n).fit()\n",
    "    adjusted_r2.append(lm_n.rsquared_adj)\n",
    "    r2.append(lm_n.rsquared)\n",
    "    \n",
    "    \n",
    "    # making predictions using rfe_15 sm model\n",
    "    X_test_rfe_n = X_test[col_n]\n",
    "\n",
    "\n",
    "    # # Adding a constant variable \n",
    "    X_test_rfe_n = sm.add_constant(X_test_rfe_n, has_constant='add')\n",
    "\n",
    "\n",
    "\n",
    "    # # Making predictions\n",
    "    y_pred = lm_n.predict(X_test_rfe_n)\n",
    "    \n",
    "    test_r2.append(r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting adjusted_r2 against n_features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(n_features_list, adjusted_r2, label=\"adjusted_r2\")\n",
    "plt.plot(n_features_list, r2, label=\"train_r2\")\n",
    "plt.plot(n_features_list, test_r2, label=\"test_r2\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with n features\n",
    "lm = LinearRegression()\n",
    "\n",
    "n_features = 6\n",
    "\n",
    "# specify number of features\n",
    "rfe_n = RFE(lm, n_features)\n",
    "\n",
    "# fit with n features\n",
    "rfe_n.fit(X_train, y_train)\n",
    "\n",
    "# subset the features selected by rfe_6\n",
    "col_n = X_train.columns[rfe_n.support_]\n",
    "\n",
    "# subsetting training data for 6 selected columns\n",
    "X_train_rfe_n = X_train[col_n]\n",
    "\n",
    "# add a constant to the model\n",
    "X_train_rfe_n = sm.add_constant(X_train_rfe_n)\n",
    "\n",
    "\n",
    "# fitting the model with 6 variables\n",
    "lm_n = sm.OLS(y_train, X_train_rfe_n).fit()\n",
    "adjusted_r2.append(lm_n.rsquared_adj)\n",
    "r2.append(lm_n.rsquared)\n",
    "\n",
    "\n",
    "# making predictions using rfe_15 sm model\n",
    "X_test_rfe_n = X_test[col_n]\n",
    "\n",
    "\n",
    "# # Adding a constant variable \n",
    "X_test_rfe_n = sm.add_constant(X_test_rfe_n, has_constant='add')\n",
    "\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "y_pred = lm_n.predict(X_test_rfe_n)\n",
    "\n",
    "test_r2.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "lm_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results \n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Evaluation\n",
    "\n",
    "Let's now evaluate the model in terms of its assumptions. We should test that:\n",
    "- The error terms are normally distributed with mean approximately 0\n",
    "- There is little correlation between the predictors\n",
    "- Homoscedasticity, i.e. the 'spread' or 'variance' of the error term (y_true-y_pred) is constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error terms\n",
    "c = [i for i in range(len(y_pred))]\n",
    "fig = plt.figure()\n",
    "plt.plot(c,y_test-y_pred, color=\"blue\", linewidth=2.5, linestyle=\"-\")\n",
    "fig.suptitle('Error Terms', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Index', fontsize=18)                      # X-label\n",
    "plt.ylabel('ytest-ypred', fontsize=16)                # Y-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the error terms to understand the distribution.\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_test-y_pred),bins=50)\n",
    "fig.suptitle('Error Terms', fontsize=20)                  # Plot heading \n",
    "plt.xlabel('y_test-y_pred', fontsize=18)                  # X-label\n",
    "plt.ylabel('Index', fontsize=16)                          # Y-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "np.mean(y_test-y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cars['price'],bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multicollinearity\n",
    "predictors = ['carwidth', 'curbweight', 'enginesize', \n",
    "             'enginelocation_rear', 'car_company_bmw', 'car_company_porsche']\n",
    "\n",
    "cors = X.loc[:, list(predictors)].corr()\n",
    "sns.heatmap(cors, annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
